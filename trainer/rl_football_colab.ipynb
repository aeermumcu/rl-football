{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸš€ RL Football - FAST Training\n\n**Optimized for speed** - 10-50x faster.\n\n1. Runtime â†’ GPU\n2. Run all cells\n3. Download weights when done"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\nimport json\nimport time\nfrom collections import deque\nimport random\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nimport keras\nfrom keras import layers, ops\nprint(f'Keras: {keras.__version__}')\n\nimport tensorflow as tf\nprint(f'GPU: {tf.config.list_physical_devices(\"GPU\")}')"
            ],
            "metadata": {
                "id": "setup"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Fast numpy game\nclass Game:\n    def __init__(self):\n        self.W, self.H = 720, 420\n        self.reset()\n\n    def reset(self):\n        self.blip = np.array([120., 210., 0., 0.])\n        self.bloop = np.array([600., 210., 0., 0.])\n        self.ball = np.array([360., 210., 0., 0.])\n        self.score = [0, 0]\n        self.time = 30.0\n        self.kick = [0, 0]\n\n    def step(self, a1, a2):\n        M = [(0,-1),(0,1),(-1,0),(1,0),(-1,-1),(1,-1),(-1,1),(1,1),(0,0),(0,0)]\n        for i, (p, a) in enumerate([(self.blip, a1), (self.bloop, a2)]):\n            if a < 8:\n                p[2] += M[a][0] * 2\n                p[3] += M[a][1] * 2\n            elif a == 8:\n                self.kick[i] = 1\n            s = np.sqrt(p[2]**2 + p[3]**2)\n            if s > 4: p[2:4] *= 4/s\n\n        for p in [self.blip, self.bloop]:\n            p[0:2] += p[2:4]\n            p[2:4] *= 0.85\n            p[0] = np.clip(p[0], 25, self.W-25)\n            p[1] = np.clip(p[1], 25, self.H-25)\n\n        self.ball[0:2] += self.ball[2:4]\n        self.ball[2:4] *= 0.98\n\n        if self.ball[1] < 12: self.ball[1], self.ball[3] = 12, -self.ball[3]*0.8\n        if self.ball[1] > self.H-12: self.ball[1], self.ball[3] = self.H-12, -self.ball[3]*0.8\n\n        gy = (self.H-120)//2\n        ing = gy < self.ball[1] < gy+120\n        if not ing:\n            if self.ball[0] < 12: self.ball[0], self.ball[2] = 12, -self.ball[2]*0.8\n            if self.ball[0] > self.W-12: self.ball[0], self.ball[2] = self.W-12, -self.ball[2]*0.8\n\n        for i, p in enumerate([self.blip, self.bloop]):\n            d = np.sqrt((self.ball[0]-p[0])**2 + (self.ball[1]-p[1])**2)\n            if 0 < d < 37:\n                n = (self.ball[0:2] - p[0:2]) / d\n                self.ball[0:2] = p[0:2] + n*37\n                pw = 12 if self.kick[i] else 6\n                self.ball[2:4] = n*pw + p[2:4]*0.5\n        self.kick = [0, 0]\n\n        ev = None\n        if ing:\n            if self.ball[0] < 0:\n                self.score[1] += 1\n                ev = 'L'\n                self._rp()\n            elif self.ball[0] > self.W:\n                self.score[0] += 1\n                ev = 'W'\n                self._rp()\n\n        self.time -= 1/60\n        return ev, self.time <= 0\n\n    def _rp(self):\n        self.blip[0:2], self.bloop[0:2] = [120,210], [600,210]\n        self.ball[:] = [360,210,0,0]\n\n    def state(self, t):\n        p, o = (self.blip, self.bloop) if t==0 else (self.bloop, self.blip)\n        d = np.sqrt((p[0]-self.ball[0])**2+(p[1]-self.ball[1])**2)/830\n        return np.array([p[0]/self.W, p[1]/self.H, self.ball[0]/self.W, self.ball[1]/self.H,\n                         np.clip(self.ball[2]/15,-1,1), np.clip(self.ball[3]/15,-1,1),\n                         o[0]/self.W, o[1]/self.H, d, 0, 0, 0], dtype=np.float32)\n\nprint('âœ… Game ready')"
            ],
            "metadata": {
                "id": "game"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def ai_act(s):\n    dx, dy = s[2]-s[0], s[3]-s[1]\n    if s[8] < 0.04: return 8\n    M = [(0,-1),(0,1),(-1,0),(1,0),(-1,-1),(1,-1),(-1,1),(1,1)]\n    mx = -1 if s[8]<0.08 else (1 if dx>0.02 else (-1 if dx<-0.02 else 0))\n    my = 1 if dy>0.02 else (-1 if dy<-0.02 else 0)\n    for i,(x,y) in enumerate(M):\n        if x==mx and y==my: return i\n    return 9\n\nprint('âœ… AI ready')"
            ],
            "metadata": {
                "id": "ai"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# DQN with Keras 3 compatible architecture\nclass DQN:\n    def __init__(self):\n        self.eps = 1.0\n        self.mem = deque(maxlen=50000)\n        self.step = 0\n        self.ld = None\n        self.model = self._build()\n        self.target = self._build()\n        self.target.set_weights(self.model.get_weights())\n\n    def _build(self):\n        inp = layers.Input(shape=(12,))\n        x = layers.Dense(256, activation='relu')(inp)\n        x = layers.Dense(256, activation='relu')(x)\n        x = layers.Dense(128, activation='relu')(x)\n        v = layers.Dense(64, activation='relu')(x)\n        v = layers.Dense(1)(v)\n        a = layers.Dense(64, activation='relu')(x)\n        a = layers.Dense(10)(a)\n        # Keras 3 compatible: use Lambda with ops.mean\n        m = layers.Lambda(lambda t: ops.mean(t, axis=1, keepdims=True))(a)\n        ac = layers.Subtract()([a, m])\n        q = layers.Add()([v, ac])\n        model = keras.Model(inp, q)\n        model.compile(optimizer=keras.optimizers.Adam(0.0005), loss='mse')\n        return model\n\n    def act(self, s):\n        if np.random.random() < self.eps:\n            return np.random.randint(10)\n        return int(np.argmax(self.model(s[np.newaxis], training=False)[0]))\n\n    def remember(self, s, a, r, s2, d):\n        self.mem.append((s,a,r,s2,d))\n\n    def train(self):\n        if len(self.mem) < 500: return\n        b = random.sample(self.mem, 64)\n        S = np.array([x[0] for x in b])\n        S2 = np.array([x[3] for x in b])\n        Q = self.model.predict(S, verbose=0)\n        Q2 = self.model.predict(S2, verbose=0)\n        QT = self.target.predict(S2, verbose=0)\n        for i,(s,a,r,s2,d) in enumerate(b):\n            Q[i][a] = r if d else r + 0.995*QT[i][np.argmax(Q2[i])]\n        self.model.fit(S, Q, verbose=0)\n        self.step += 1\n        if self.step % 500 == 0:\n            self.target.set_weights(self.model.get_weights())\n\n    def reward(self, g, ev):\n        p, b, o = g.blip, g.ball, g.bloop\n        d = np.sqrt((p[0]-b[0])**2+(p[1]-b[1])**2)\n        r = 500 if ev=='W' else (-300 if ev=='L' else 0)\n        r += (1-d/830)*5\n        if d < 40: r += 10\n        if self.ld:\n            dd = self.ld - d\n            r += dd*0.5\n            if dd > 2: r += 3\n        self.ld = d\n        sp = np.sqrt(p[2]**2+p[3]**2)\n        if sp < 0.5 and d > 50: r -= 8\n        if sp > 1: r += 1\n        if b[2] > 2 and d < 80: r += 8\n        if abs(b[0]-720) < 100: r += 5\n        if (p[0]<80 or p[0]>640) and (p[1]<80 or p[1]>340):\n            r -= 5\n            if d > 100: r -= 5\n        if d > 300: r -= 5\n        elif d > 200: r -= 3\n        elif d > 150: r -= 1\n        od = np.sqrt((o[0]-b[0])**2+(o[1]-b[1])**2)\n        if od < d and d > 60: r -= 2\n        return r - 0.1\n\n    def reset(self):\n        self.ld = None\n        self.eps = max(0.02, self.eps * 0.9999)\n\n    def save(self, f):\n        w = self.model.get_weights()\n        json.dump({'weights':[{'shape':list(x.shape),'data':x.flatten().tolist()} for x in w],\n                   'epsilon':self.eps,'trainStepCount':self.step}, open(f,'w'))\n\nprint('âœ… DQN ready')"
            ],
            "metadata": {
                "id": "dqn"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def train(n=100000):\n    g, a = Game(), DQN()\n    st = {'W':0,'L':0,'D':0,'G':0}\n    t0 = time.time()\n    print('='*50+'\\nðŸš€ Training\\n'+'='*50)\n\n    for ep in range(1, n+1):\n        g.reset()\n        done = False\n        c = 0\n        while not done:\n            c += 1\n            s1 = g.state(0)\n            s2 = g.state(1)\n            a1 = a.act(s1)\n            a2 = ai_act(s2)\n            ev, done = g.step(a1, a2)\n            r = a.reward(g, ev)\n            a.remember(s1, a1, r, g.state(0), done)\n            if ev: st['G'] += 1\n            if c % 4 == 0: a.train()\n\n        w = 'W' if g.score[0]>g.score[1] else ('L' if g.score[1]>g.score[0] else 'D')\n        st[w] += 1\n        a.reset()\n\n        if ep % 100 == 0 or ep == 1:\n            el = time.time() - t0\n            sp = ep/el\n            eta = (n-ep)/sp if sp>0 else 0\n            print(f'Ep {ep}/{n} | Îµ:{a.eps:.3f} | W:{st[\"W\"]} L:{st[\"L\"]} D:{st[\"D\"]} | G:{st[\"G\"]} | {sp:.1f}/s | ETA:{eta/3600:.1f}h')\n\n        if ep % 5000 == 0:\n            a.save(f'w_{ep}.json')\n            print(f'ðŸ’¾ Saved')\n\n    a.save('final.json')\n    print('âœ… Done!')\n    return a, st\n\nprint('âœ… Ready')"
            ],
            "metadata": {
                "id": "train"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "agent, stats = train(100000)"
            ],
            "metadata": {
                "id": "run"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import files\nw = json.load(open('final.json'))\nout = {'version':2,'blipAgent':w,'bloopAgent':w,'blip':w,'bloop':w,'stats':stats}\njson.dump(out, open('trained.json','w'))\nfiles.download('trained.json')"
            ],
            "metadata": {
                "id": "dl"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}