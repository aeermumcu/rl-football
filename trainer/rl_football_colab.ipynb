{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸ¤– RL Football Champions - GPU Training\n",
                "\n",
                "This notebook trains the DQN agent on Google Colab's GPU for much faster training.\n",
                "\n",
                "**Instructions:**\n",
                "1. Go to Runtime â†’ Change runtime type â†’ Select **GPU**\n",
                "2. Run all cells (Runtime â†’ Run all)\n",
                "3. Wait for training to complete\n",
                "4. Download the weights file\n",
                "\n",
                "Expected time: ~2-4 hours for 100k episodes"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Check GPU availability\n",
                "import tensorflow as tf\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
                "if tf.config.list_physical_devices('GPU'):\n",
                "    print(\"âœ… GPU is ready!\")\n",
                "else:\n",
                "    print(\"âš ï¸ No GPU detected. Go to Runtime â†’ Change runtime type â†’ GPU\")"
            ],
            "metadata": {
                "id": "check_gpu"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "import json\n",
                "import time\n",
                "from collections import deque\n",
                "import random\n",
                "import keras\n",
                "from keras import layers, ops\n",
                "\n",
                "print(\"âœ… Libraries imported\")"
            ],
            "metadata": {
                "id": "imports"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Game Simulation"
            ],
            "metadata": {
                "id": "game_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "class Player:\n",
                "    def __init__(self, x, y, team):\n",
                "        self.x = x\n",
                "        self.y = y\n",
                "        self.start_x = x\n",
                "        self.start_y = y\n",
                "        self.team = team\n",
                "        self.vx = 0.0\n",
                "        self.vy = 0.0\n",
                "        self.radius = 25\n",
                "        self.speed = 4\n",
                "        self.friction = 0.85\n",
                "        self.kick_animation = 0\n",
                "\n",
                "    def reset(self):\n",
                "        self.x = self.start_x\n",
                "        self.y = self.start_y\n",
                "        self.vx = 0.0\n",
                "        self.vy = 0.0\n",
                "\n",
                "    def update(self):\n",
                "        self.x += self.vx\n",
                "        self.y += self.vy\n",
                "        self.vx *= self.friction\n",
                "        self.vy *= self.friction\n",
                "\n",
                "    def move(self, dx, dy):\n",
                "        self.vx += dx * self.speed * 0.5\n",
                "        self.vy += dy * self.speed * 0.5\n",
                "        current_speed = np.sqrt(self.vx**2 + self.vy**2)\n",
                "        if current_speed > self.speed:\n",
                "            self.vx = (self.vx / current_speed) * self.speed\n",
                "            self.vy = (self.vy / current_speed) * self.speed\n",
                "\n",
                "    def kick(self):\n",
                "        self.kick_animation = 1\n",
                "\n",
                "\n",
                "class Ball:\n",
                "    def __init__(self, x, y):\n",
                "        self.x = x\n",
                "        self.y = y\n",
                "        self.start_x = x\n",
                "        self.start_y = y\n",
                "        self.vx = 0.0\n",
                "        self.vy = 0.0\n",
                "        self.radius = 12\n",
                "\n",
                "    def reset(self):\n",
                "        self.x = self.start_x\n",
                "        self.y = self.start_y\n",
                "        self.vx = 0.0\n",
                "        self.vy = 0.0\n",
                "\n",
                "\n",
                "class Game:\n",
                "    def __init__(self, match_time=30):\n",
                "        self.width = 800\n",
                "        self.height = 500\n",
                "        self.padding = 40\n",
                "\n",
                "        self.field_left = self.padding\n",
                "        self.field_right = self.width - self.padding\n",
                "        self.field_top = self.padding\n",
                "        self.field_bottom = self.height - self.padding\n",
                "        self.field_width = self.field_right - self.field_left\n",
                "        self.field_height = self.field_bottom - self.field_top\n",
                "\n",
                "        self.goal_height = 120\n",
                "        self.goal_y = self.height / 2\n",
                "\n",
                "        self.blip = Player(self.field_left + 80, self.height / 2, 'blip')\n",
                "        self.bloop = Player(self.field_right - 80, self.height / 2, 'bloop')\n",
                "        self.ball = Ball(self.width / 2, self.height / 2)\n",
                "\n",
                "        self.blip_score = 0\n",
                "        self.bloop_score = 0\n",
                "        self.match_time = match_time\n",
                "        self.time_remaining = match_time\n",
                "\n",
                "    def reset(self):\n",
                "        self.blip.reset()\n",
                "        self.bloop.reset()\n",
                "        self.ball.reset()\n",
                "        self.time_remaining = self.match_time\n",
                "\n",
                "    def reset_scores(self):\n",
                "        self.blip_score = 0\n",
                "        self.bloop_score = 0\n",
                "\n",
                "    def update(self):\n",
                "        self.time_remaining -= 1/60\n",
                "\n",
                "        self.blip.update()\n",
                "        self.bloop.update()\n",
                "        self._update_ball()\n",
                "        self._check_collision(self.blip)\n",
                "        self._check_collision(self.bloop)\n",
                "        self._constrain_player(self.blip)\n",
                "        self._constrain_player(self.bloop)\n",
                "\n",
                "        event = self._check_goal()\n",
                "        done = self.time_remaining <= 0\n",
                "\n",
                "        return event, done\n",
                "\n",
                "    def _update_ball(self):\n",
                "        self.ball.x += self.ball.vx\n",
                "        self.ball.y += self.ball.vy\n",
                "        self.ball.vx *= 0.98\n",
                "        self.ball.vy *= 0.98\n",
                "\n",
                "        if self.ball.y - self.ball.radius < self.field_top:\n",
                "            self.ball.y = self.field_top + self.ball.radius\n",
                "            self.ball.vy *= -0.8\n",
                "        if self.ball.y + self.ball.radius > self.field_bottom:\n",
                "            self.ball.y = self.field_bottom - self.ball.radius\n",
                "            self.ball.vy *= -0.8\n",
                "\n",
                "        in_goal_range = (self.goal_y - self.goal_height/2 < self.ball.y < self.goal_y + self.goal_height/2)\n",
                "        if not in_goal_range:\n",
                "            if self.ball.x - self.ball.radius < self.field_left:\n",
                "                self.ball.x = self.field_left + self.ball.radius\n",
                "                self.ball.vx *= -0.8\n",
                "            if self.ball.x + self.ball.radius > self.field_right:\n",
                "                self.ball.x = self.field_right - self.ball.radius\n",
                "                self.ball.vx *= -0.8\n",
                "\n",
                "    def _check_collision(self, player):\n",
                "        dx = self.ball.x - player.x\n",
                "        dy = self.ball.y - player.y\n",
                "        dist = np.sqrt(dx**2 + dy**2)\n",
                "        min_dist = player.radius + self.ball.radius\n",
                "\n",
                "        if dist < min_dist and dist > 0:\n",
                "            nx = dx / dist\n",
                "            ny = dy / dist\n",
                "            self.ball.x = player.x + nx * min_dist\n",
                "            self.ball.y = player.y + ny * min_dist\n",
                "            kick_power = 12 if player.kick_animation > 0 else 6\n",
                "            self.ball.vx = nx * kick_power + player.vx * 0.5\n",
                "            self.ball.vy = ny * kick_power + player.vy * 0.5\n",
                "            player.kick_animation = 0\n",
                "\n",
                "    def _constrain_player(self, player):\n",
                "        margin = player.radius\n",
                "        if player.x - margin < self.field_left:\n",
                "            player.x = self.field_left + margin\n",
                "            player.vx = 0\n",
                "        if player.x + margin > self.field_right:\n",
                "            player.x = self.field_right - margin\n",
                "            player.vx = 0\n",
                "        if player.y - margin < self.field_top:\n",
                "            player.y = self.field_top + margin\n",
                "            player.vy = 0\n",
                "        if player.y + margin > self.field_bottom:\n",
                "            player.y = self.field_bottom - margin\n",
                "            player.vy = 0\n",
                "\n",
                "    def _check_goal(self):\n",
                "        in_goal_y = (self.goal_y - self.goal_height/2 < self.ball.y < self.goal_y + self.goal_height/2)\n",
                "\n",
                "        if in_goal_y and self.ball.x < self.field_left:\n",
                "            self.bloop_score += 1\n",
                "            self._reset_after_goal()\n",
                "            return 'bloop_scored'\n",
                "\n",
                "        if in_goal_y and self.ball.x > self.field_right:\n",
                "            self.blip_score += 1\n",
                "            self._reset_after_goal()\n",
                "            return 'blip_scored'\n",
                "\n",
                "        return None\n",
                "\n",
                "    def _reset_after_goal(self):\n",
                "        self.ball.reset()\n",
                "        self.blip.x = self.blip.start_x\n",
                "        self.blip.y = self.blip.start_y\n",
                "        self.bloop.x = self.bloop.start_x\n",
                "        self.bloop.y = self.bloop.start_y\n",
                "\n",
                "    def get_winner(self):\n",
                "        if self.blip_score > self.bloop_score:\n",
                "            return 'blip'\n",
                "        elif self.bloop_score > self.blip_score:\n",
                "            return 'bloop'\n",
                "        return 'draw'\n",
                "\n",
                "print(\"âœ… Game simulation ready\")"
            ],
            "metadata": {
                "id": "game"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Actions"
            ],
            "metadata": {
                "id": "actions_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "ACTIONS = [\n",
                "    {'dx': 0, 'dy': -1, 'kick': False, 'name': 'up'},\n",
                "    {'dx': 0, 'dy': 1, 'kick': False, 'name': 'down'},\n",
                "    {'dx': -1, 'dy': 0, 'kick': False, 'name': 'left'},\n",
                "    {'dx': 1, 'dy': 0, 'kick': False, 'name': 'right'},\n",
                "    {'dx': -1, 'dy': -1, 'kick': False, 'name': 'up-left'},\n",
                "    {'dx': 1, 'dy': -1, 'kick': False, 'name': 'up-right'},\n",
                "    {'dx': -1, 'dy': 1, 'kick': False, 'name': 'down-left'},\n",
                "    {'dx': 1, 'dy': 1, 'kick': False, 'name': 'down-right'},\n",
                "    {'dx': 0, 'dy': 0, 'kick': True, 'name': 'kick'},\n",
                "    {'dx': 0, 'dy': 0, 'kick': False, 'name': 'stay'}\n",
                "]\n",
                "\n",
                "def apply_action(player, action):\n",
                "    if action['dx'] != 0 or action['dy'] != 0:\n",
                "        player.move(action['dx'], action['dy'])\n",
                "    if action['kick']:\n",
                "        player.kick()\n",
                "\n",
                "print(f\"âœ… {len(ACTIONS)} actions defined\")"
            ],
            "metadata": {
                "id": "actions"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Simple AI Opponent"
            ],
            "metadata": {
                "id": "simple_ai_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "class SimpleAI:\n",
                "    def __init__(self, team):\n",
                "        self.team = team\n",
                "        self.last_action = 0\n",
                "\n",
                "    def get_state(self, player, ball, opponent, field_width, field_height):\n",
                "        player_x = player.x / field_width\n",
                "        player_y = player.y / field_height\n",
                "        ball_x = ball.x / field_width\n",
                "        ball_y = ball.y / field_height\n",
                "        ball_vx = np.clip(ball.vx / 15, -1, 1)\n",
                "        ball_vy = np.clip(ball.vy / 15, -1, 1)\n",
                "        opp_x = opponent.x / field_width\n",
                "        opp_y = opponent.y / field_height\n",
                "\n",
                "        max_dist = np.sqrt(field_width**2 + field_height**2)\n",
                "        dist_ball = np.sqrt((player.x - ball.x)**2 + (player.y - ball.y)**2) / max_dist\n",
                "        angle_ball = (np.arctan2(ball.y - player.y, ball.x - player.x) + np.pi) / (2 * np.pi)\n",
                "\n",
                "        goal_x = field_width if self.team == 'blip' else 0\n",
                "        goal_y = field_height / 2\n",
                "        dist_goal = np.sqrt((player.x - goal_x)**2 + (player.y - goal_y)**2) / max_dist\n",
                "        angle_goal = (np.arctan2(goal_y - player.y, goal_x - player.x) + np.pi) / (2 * np.pi)\n",
                "\n",
                "        return np.array([player_x, player_y, ball_x, ball_y, ball_vx, ball_vy,\n",
                "                        opp_x, opp_y, dist_ball, angle_ball, dist_goal, angle_goal])\n",
                "\n",
                "    def choose_action(self, state):\n",
                "        player_x, player_y = state[0], state[1]\n",
                "        ball_x, ball_y = state[2], state[3]\n",
                "        dist_to_ball = state[8]\n",
                "\n",
                "        dx_to_ball = ball_x - player_x\n",
                "        dy_to_ball = ball_y - player_y\n",
                "\n",
                "        if dist_to_ball < 0.08:\n",
                "            goal_dir = -1 if self.team == 'bloop' else 1\n",
                "            if dist_to_ball < 0.04:\n",
                "                self.last_action = 8\n",
                "                return ACTIONS[8]\n",
                "            move_dx = goal_dir\n",
                "            move_dy = 1 if dy_to_ball > 0.01 else (-1 if dy_to_ball < -0.01 else 0)\n",
                "            for i in range(8):\n",
                "                if ACTIONS[i]['dx'] == move_dx and ACTIONS[i]['dy'] == move_dy:\n",
                "                    self.last_action = i\n",
                "                    return ACTIONS[i]\n",
                "\n",
                "        threshold = 0.02\n",
                "        move_dx = 1 if dx_to_ball > threshold else (-1 if dx_to_ball < -threshold else 0)\n",
                "        move_dy = 1 if dy_to_ball > threshold else (-1 if dy_to_ball < -threshold else 0)\n",
                "\n",
                "        for i in range(8):\n",
                "            if ACTIONS[i]['dx'] == move_dx and ACTIONS[i]['dy'] == move_dy:\n",
                "                self.last_action = i\n",
                "                return ACTIONS[i]\n",
                "\n",
                "        return ACTIONS[3]\n",
                "\n",
                "    def reset(self):\n",
                "        pass\n",
                "\n",
                "print(\"âœ… SimpleAI opponent ready\")"
            ],
            "metadata": {
                "id": "simple_ai"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Dueling DQN Agent"
            ],
            "metadata": {
                "id": "dqn_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "class DuelingDQNAgent:\n",
                "    def __init__(self, team):\n",
                "        self.team = team\n",
                "        self.state_size = 12\n",
                "        self.action_size = 10\n",
                "\n",
                "        self.learning_rate = 0.0005\n",
                "        self.gamma = 0.995\n",
                "        self.epsilon = 1.0\n",
                "        self.epsilon_min = 0.02\n",
                "        self.epsilon_decay = 0.9999\n",
                "\n",
                "        self.memory = deque(maxlen=50000)\n",
                "        self.batch_size = 64\n",
                "        self.min_memory_size = 500\n",
                "\n",
                "        self.target_update_freq = 500\n",
                "        self.train_step = 0\n",
                "\n",
                "        self.model = self._build_model()\n",
                "        self.target_model = self._build_model()\n",
                "        self.update_target_network()\n",
                "\n",
                "        self.last_dist_to_ball = None\n",
                "        self.last_action = 0\n",
                "\n",
                "    def _build_model(self):\n",
                "        inputs = layers.Input(shape=(self.state_size,))\n",
                "\n",
                "        x = layers.Dense(256, activation='relu', kernel_initializer='he_normal')(inputs)\n",
                "        x = layers.Dense(256, activation='relu', kernel_initializer='he_normal')(x)\n",
                "        x = layers.Dense(128, activation='relu', kernel_initializer='he_normal')(x)\n",
                "\n",
                "        # Value stream\n",
                "        value = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
                "        value = layers.Dense(1, kernel_initializer='he_normal', name='value')(value)\n",
                "\n",
                "        # Advantage stream\n",
                "        advantage = layers.Dense(64, activation='relu', kernel_initializer='he_normal')(x)\n",
                "        advantage = layers.Dense(self.action_size, kernel_initializer='he_normal', name='advantage')(advantage)\n",
                "\n",
                "        # Combine using Keras 3 compatible ops\n",
                "        mean_adv = layers.Lambda(lambda a: ops.mean(a, axis=1, keepdims=True))(advantage)\n",
                "        adv_centered = layers.Subtract()([advantage, mean_adv])\n",
                "        q_values = layers.Add()([value, adv_centered])\n",
                "\n",
                "        model = keras.Model(inputs=inputs, outputs=q_values)\n",
                "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate), loss='mse')\n",
                "        return model\n",
                "\n",
                "    def update_target_network(self):\n",
                "        self.target_model.set_weights(self.model.get_weights())\n",
                "\n",
                "    def get_state(self, player, ball, opponent, field_width, field_height):\n",
                "        player_x = player.x / field_width\n",
                "        player_y = player.y / field_height\n",
                "        ball_x = ball.x / field_width\n",
                "        ball_y = ball.y / field_height\n",
                "        ball_vx = np.clip(ball.vx / 15, -1, 1)\n",
                "        ball_vy = np.clip(ball.vy / 15, -1, 1)\n",
                "        opp_x = opponent.x / field_width\n",
                "        opp_y = opponent.y / field_height\n",
                "\n",
                "        max_dist = np.sqrt(field_width**2 + field_height**2)\n",
                "        dist_ball = np.sqrt((player.x - ball.x)**2 + (player.y - ball.y)**2) / max_dist\n",
                "        angle_ball = (np.arctan2(ball.y - player.y, ball.x - player.x) + np.pi) / (2 * np.pi)\n",
                "\n",
                "        goal_x = field_width if self.team == 'blip' else 0\n",
                "        goal_y = field_height / 2\n",
                "        dist_goal = np.sqrt((player.x - goal_x)**2 + (player.y - goal_y)**2) / max_dist\n",
                "        angle_goal = (np.arctan2(goal_y - player.y, goal_x - player.x) + np.pi) / (2 * np.pi)\n",
                "\n",
                "        return np.array([player_x, player_y, ball_x, ball_y, ball_vx, ball_vy,\n",
                "                        opp_x, opp_y, dist_ball, angle_ball, dist_goal, angle_goal])\n",
                "\n",
                "    def choose_action(self, state, training=True):\n",
                "        if training and np.random.random() < self.epsilon:\n",
                "            action_idx = np.random.randint(self.action_size)\n",
                "        else:\n",
                "            q_values = self.model.predict(state.reshape(1, -1), verbose=0)\n",
                "            action_idx = np.argmax(q_values[0])\n",
                "        self.last_action = action_idx\n",
                "        return ACTIONS[action_idx]\n",
                "\n",
                "    def remember(self, state, action, reward, next_state, done):\n",
                "        self.memory.append((state, action, reward, next_state, done))\n",
                "\n",
                "    def train(self):\n",
                "        if len(self.memory) < self.min_memory_size:\n",
                "            return\n",
                "\n",
                "        batch = random.sample(self.memory, self.batch_size)\n",
                "        states = np.array([e[0] for e in batch])\n",
                "        next_states = np.array([e[3] for e in batch])\n",
                "\n",
                "        current_qs = self.model.predict(states, verbose=0)\n",
                "        next_qs_main = self.model.predict(next_states, verbose=0)\n",
                "        next_qs_target = self.target_model.predict(next_states, verbose=0)\n",
                "\n",
                "        for i, (state, action, reward, next_state, done) in enumerate(batch):\n",
                "            if done:\n",
                "                current_qs[i][action] = reward\n",
                "            else:\n",
                "                best_action = np.argmax(next_qs_main[i])\n",
                "                current_qs[i][action] = reward + self.gamma * next_qs_target[i][best_action]\n",
                "\n",
                "        self.model.fit(states, current_qs, epochs=1, verbose=0)\n",
                "\n",
                "        self.train_step += 1\n",
                "        if self.train_step % self.target_update_freq == 0:\n",
                "            self.update_target_network()\n",
                "\n",
                "    def calculate_reward(self, player, ball, opponent, event, field_width):\n",
                "        reward = 0\n",
                "        field_height = 420\n",
                "        dist_to_ball = np.sqrt((player.x - ball.x)**2 + (player.y - ball.y)**2)\n",
                "\n",
                "        if event == 'scored':\n",
                "            reward += 500\n",
                "        elif event == 'conceded':\n",
                "            reward -= 300\n",
                "\n",
                "        max_dist = np.sqrt(field_width**2 + field_height**2)\n",
                "        normalized_dist = dist_to_ball / max_dist\n",
                "        reward += (1 - normalized_dist) * 5\n",
                "\n",
                "        if dist_to_ball < 40:\n",
                "            reward += 10\n",
                "\n",
                "        if self.last_dist_to_ball is not None:\n",
                "            dist_delta = self.last_dist_to_ball - dist_to_ball\n",
                "            reward += dist_delta * 0.5\n",
                "            if dist_delta > 2:\n",
                "                reward += 3\n",
                "        self.last_dist_to_ball = dist_to_ball\n",
                "\n",
                "        player_speed = np.sqrt(player.vx**2 + player.vy**2)\n",
                "        if player_speed < 0.5 and dist_to_ball > 50:\n",
                "            reward -= 8\n",
                "        if player_speed > 1:\n",
                "            reward += 1\n",
                "\n",
                "        attacking_goal_x = field_width if self.team == 'blip' else 0\n",
                "        ball_moving_toward_goal = (self.team == 'blip' and ball.vx > 2) or (self.team == 'bloop' and ball.vx < -2)\n",
                "        if ball_moving_toward_goal and dist_to_ball < 80:\n",
                "            reward += 8\n",
                "\n",
                "        dist_ball_to_goal = abs(ball.x - attacking_goal_x)\n",
                "        if dist_ball_to_goal < 100:\n",
                "            reward += 5\n",
                "\n",
                "        corner_margin = 80\n",
                "        in_corner = (player.x < corner_margin or player.x > field_width - corner_margin) and \\\n",
                "                    (player.y < corner_margin or player.y > field_height - corner_margin)\n",
                "        if in_corner:\n",
                "            reward -= 5\n",
                "            if dist_to_ball > 100:\n",
                "                reward -= 5\n",
                "\n",
                "        if dist_to_ball > 300:\n",
                "            reward -= 5\n",
                "        elif dist_to_ball > 200:\n",
                "            reward -= 3\n",
                "        elif dist_to_ball > 150:\n",
                "            reward -= 1\n",
                "\n",
                "        opp_dist = np.sqrt((opponent.x - ball.x)**2 + (opponent.y - ball.y)**2)\n",
                "        if opp_dist < dist_to_ball and dist_to_ball > 60:\n",
                "            reward -= 2\n",
                "\n",
                "        reward -= 0.1\n",
                "        return reward\n",
                "\n",
                "    def reset(self):\n",
                "        self.last_dist_to_ball = None\n",
                "        if self.epsilon > self.epsilon_min:\n",
                "            self.epsilon *= self.epsilon_decay\n",
                "\n",
                "    def save_weights(self, filepath):\n",
                "        weights = self.model.get_weights()\n",
                "        weight_data = [{'shape': list(w.shape), 'data': w.flatten().tolist()} for w in weights]\n",
                "        save_data = {'weights': weight_data, 'epsilon': self.epsilon, 'trainStepCount': self.train_step}\n",
                "        with open(filepath, 'w') as f:\n",
                "            json.dump(save_data, f)\n",
                "\n",
                "print(\"âœ… Dueling DQN Agent ready\")"
            ],
            "metadata": {
                "id": "dqn_agent"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Training Loop"
            ],
            "metadata": {
                "id": "training_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def train(num_episodes=100000, match_time=30, save_every=5000):\n",
                "    game = Game(match_time=match_time)\n",
                "    blip_agent = DuelingDQNAgent('blip')\n",
                "    bloop_ai = SimpleAI('bloop')\n",
                "\n",
                "    stats = {'blip_wins': 0, 'bloop_wins': 0, 'draws': 0, 'total_goals': 0}\n",
                "    start_time = time.time()\n",
                "\n",
                "    print(\"=\" * 50)\n",
                "    print(\"ðŸ¤– RL Football Champions - GPU Training\")\n",
                "    print(\"=\" * 50)\n",
                "    print(f\"Episodes: {num_episodes}\")\n",
                "    print(f\"Match time: {match_time}s\")\n",
                "    print(\"Opponent: SimpleAI (ball-chaser)\")\n",
                "    print(\"=\" * 50)\n",
                "\n",
                "    for episode in range(1, num_episodes + 1):\n",
                "        game.reset()\n",
                "        game.reset_scores()\n",
                "        steps = 0\n",
                "        done = False\n",
                "\n",
                "        while not done:\n",
                "            steps += 1\n",
                "            blip_state = blip_agent.get_state(game.blip, game.ball, game.bloop, game.field_width, game.field_height)\n",
                "            bloop_state = bloop_ai.get_state(game.bloop, game.ball, game.blip, game.field_width, game.field_height)\n",
                "\n",
                "            blip_action = blip_agent.choose_action(blip_state, training=True)\n",
                "            bloop_action = bloop_ai.choose_action(bloop_state)\n",
                "\n",
                "            apply_action(game.blip, blip_action)\n",
                "            apply_action(game.bloop, bloop_action)\n",
                "\n",
                "            event, done = game.update()\n",
                "\n",
                "            blip_event = None\n",
                "            if event == 'blip_scored':\n",
                "                blip_event = 'scored'\n",
                "                stats['total_goals'] += 1\n",
                "            elif event == 'bloop_scored':\n",
                "                blip_event = 'conceded'\n",
                "                stats['total_goals'] += 1\n",
                "\n",
                "            blip_reward = blip_agent.calculate_reward(game.blip, game.ball, game.bloop, blip_event, game.field_width)\n",
                "            new_blip_state = blip_agent.get_state(game.blip, game.ball, game.bloop, game.field_width, game.field_height)\n",
                "            blip_agent.remember(blip_state, blip_agent.last_action, blip_reward, new_blip_state, done)\n",
                "\n",
                "            if steps % 4 == 0:\n",
                "                blip_agent.train()\n",
                "\n",
                "        winner = game.get_winner()\n",
                "        if winner == 'blip':\n",
                "            stats['blip_wins'] += 1\n",
                "        elif winner == 'bloop':\n",
                "            stats['bloop_wins'] += 1\n",
                "        else:\n",
                "            stats['draws'] += 1\n",
                "\n",
                "        blip_agent.reset()\n",
                "        bloop_ai.reset()\n",
                "\n",
                "        if episode % 100 == 0 or episode == 1:\n",
                "            elapsed = time.time() - start_time\n",
                "            eps_per_sec = episode / elapsed\n",
                "            remaining = (num_episodes - episode) / eps_per_sec if eps_per_sec > 0 else 0\n",
                "            eta = f\"{remaining/60:.1f}m\" if remaining < 3600 else f\"{remaining/3600:.1f}h\"\n",
                "            print(f\"Episode {episode}/{num_episodes} | Îµ: {blip_agent.epsilon:.3f} | Blip: {stats['blip_wins']} | Bloop: {stats['bloop_wins']} | Draws: {stats['draws']} | Goals: {stats['total_goals']} | Speed: {eps_per_sec:.1f} ep/s | ETA: {eta}\")\n",
                "\n",
                "        if episode % save_every == 0:\n",
                "            blip_agent.save_weights(f'blip_weights_{episode}.json')\n",
                "            print(f\"ðŸ’¾ Saved weights at episode {episode}\")\n",
                "\n",
                "    blip_agent.save_weights('blip_weights_final.json')\n",
                "    print(\"=\" * 50)\n",
                "    print(\"âœ… Training complete!\")\n",
                "    print(f\"Final stats: Blip {stats['blip_wins']} | Bloop {stats['bloop_wins']} | Draws {stats['draws']}\")\n",
                "    print(f\"Total goals: {stats['total_goals']}\")\n",
                "    print(\"=\" * 50)\n",
                "    return blip_agent, stats\n",
                "\n",
                "print(\"âœ… Training function ready\")"
            ],
            "metadata": {
                "id": "training_loop"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ðŸš€ Start Training!"
            ],
            "metadata": {
                "id": "start_training_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "agent, stats = train(num_episodes=100000, match_time=30, save_every=5000)"
            ],
            "metadata": {
                "id": "start_training"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Download Weights"
            ],
            "metadata": {
                "id": "download_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Create browser-compatible format\n",
                "with open('blip_weights_final.json', 'r') as f:\n",
                "    blip_data = json.load(f)\n",
                "\n",
                "browser_data = {\n",
                "    'version': 2,\n",
                "    'aiType': 'dqn',\n",
                "    'episodeCount': 100000,\n",
                "    'trainedAgainst': 'SimpleAI',\n",
                "    'stats': stats,\n",
                "    'blipAgent': blip_data,\n",
                "    'bloopAgent': blip_data,\n",
                "    'blip': blip_data,\n",
                "    'bloop': blip_data\n",
                "}\n",
                "\n",
                "with open('rl_football_trained.json', 'w') as f:\n",
                "    json.dump(browser_data, f)\n",
                "\n",
                "print(\"âœ… Browser-compatible weights saved!\")\n",
                "files.download('rl_football_trained.json')"
            ],
            "metadata": {
                "id": "download"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}